{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "id": "I1hIaFzf40l7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10e8f07-625c-4aa6-e077-b857a7ae0719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.34.129-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.129 (from boto3)\n",
            "  Downloading botocore-1.34.129-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.129->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.129->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.129->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.129 botocore-1.34.129 jmespath-1.0.1 s3transfer-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCgeFK8O2t6G"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "from boto3.dynamodb.conditions import Key, Attr\n",
        "import json\n",
        "import calendar;\n",
        "import time;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dynamodb = boto3.resource('dynamodb',\n",
        "    region_name =\"us-east-1\",\n",
        "    aws_access_key_id=\"AKIAZI2LCD2QHF4KI2NZ\",\n",
        "    aws_secret_access_key=\"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\")"
      ],
      "metadata": {
        "id": "cxxgP9Sm7A1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3 = boto3.resource('s3',\n",
        "    aws_access_key_id=\"AKIAZI2LCD2QHF4KI2NZ\",\n",
        "    aws_secret_access_key=\"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\")"
      ],
      "metadata": {
        "id": "Fjv77feK4SAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3.Bucket(\"facialvideorecordings\").download_file(\"shape_predictor_68_face_landmarks.dat\", 'shape_predictor_68_face_landmarks.dat')"
      ],
      "metadata": {
        "id": "qxgi6IjT4tkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gmt stores current gmtime\n",
        "gmt = time.gmtime()\n",
        "\n",
        "# ts stores timestamp\n",
        "ts = calendar.timegm(gmt)\n",
        "ts = 1718716582280\n",
        "\n",
        "#/content/1718792595861.mkv\n",
        "\n",
        "table = dynamodb.Table('FacialVideoData')\n",
        "response = table.scan(\n",
        "    FilterExpression=Attr('UserId').eq('Vimukthi') & Attr('Time').eq(\"1718792595861\")\n",
        ")\n",
        "items = response['Items']\n",
        "print(items)\n",
        "print(len(items))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfR1EU837ew3",
        "outputId": "2c664473-836e-4699-c3e7-20df7d2957a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': 'fe1175c8-d5c1-43c9-b595-b44f43484dfd', 'FilePath': '1718792595861_7'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '989b52c7-dbd3-4c25-802e-7da595443671', 'FilePath': '1718792595861_10'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '00300505-d127-45d6-bc05-d1c14442107d', 'FilePath': '1718792595861_15'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': 'd8ed1096-d5b2-4703-a02b-1995e76e096b', 'FilePath': '1718792595861_4'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '8207de1e-f41e-480f-9fa4-227441feac8f', 'FilePath': '1718792595861_2'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': 'b3cf0e5a-d749-438d-b3bd-ef05aeecba57', 'FilePath': '1718792595861_14'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '7f58c5b3-4f09-450a-97af-997d8d951467', 'FilePath': '1718792595861_13'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '6df83fc3-bf85-4d57-abb8-2850809744f5', 'FilePath': '1718792595861_3'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '007547f2-56a8-4357-a48b-78a319f16428', 'FilePath': '1718792595861_1'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '0d177b95-4cdd-4640-a998-ef0cf9caa75d', 'FilePath': '1718792595861_8'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '1bc80304-a7d2-49fa-989b-20d59b7f7ccc', 'FilePath': '1718792595861_5'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': 'e400a04f-25b2-45f2-b5dd-bc18a7188c89', 'FilePath': '1718792595861_11'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '9efc9e63-1f32-41bb-a81a-996d722724bc', 'FilePath': '1718792595861_12'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '5ef669ab-c787-4bd5-bc60-fd6a66fa5268', 'FilePath': '1718792595861_6'}, {'UserId': 'Vimukthi', 'Time': '1718792595861', 'RecordId': '89b3fa88-6b6e-431e-922f-2e93e9db3f4a', 'FilePath': '1718792595861_9'}]\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestamps = []\n",
        "record_num_per_time_stamp = {}\n",
        "records_per_timestamp = {}\n",
        "for record in items:\n",
        "  time_str = record['Time']\n",
        "  timestamps.append(int(time_str))\n",
        "  timestamp_in_filepath = record['FilePath'].split(\"_\")[0]\n",
        "  if timestamp_in_filepath not in records_per_timestamp.keys():\n",
        "    records_per_timestamp[timestamp_in_filepath] = [int(record['FilePath'].split(\"_\")[1])]\n",
        "    record_num_per_time_stamp[timestamp_in_filepath] = 1;\n",
        "  else:\n",
        "    records_per_timestamp[timestamp_in_filepath].append(int(record['FilePath'].split(\"_\")[1]))\n",
        "    record_num_per_time_stamp[timestamp_in_filepath] += 1;\n",
        "timestamps = list(set(timestamps))\n",
        "for key, value in records_per_timestamp.items():\n",
        "  records_per_timestamp[key] = sorted(value)\n",
        "print(sorted(timestamps))\n",
        "print(records_per_timestamp)\n",
        "print(record_num_per_time_stamp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WsJtsG1-Fmr",
        "outputId": "4ea39a4e-e5f8-4ea6-d432-1b11aa0a2aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1718792595861]\n",
            "{'1718792595861': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}\n",
            "{'1718792595861': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latest_timestamp = timestamps[-1]\n",
        "file_record_keys = records_per_timestamp[str(latest_timestamp)]\n",
        "for record_key in file_record_keys:\n",
        "  filename = str(latest_timestamp)+ \"_\" + str(record_key)\n",
        "  s3.Bucket(\"facialvideorecordings\").download_file( filename , filename)\n"
      ],
      "metadata": {
        "id": "_3sE-a7jAPmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "base64string = \"\"\n",
        "for i in range(1, 6):\n",
        "  filename = str(i) + \".txt\"\n",
        "  with open(filename, 'r') as file:\n",
        "    print(filename)\n",
        "    data = file.read().rstrip()\n",
        "    print(len(data))\n",
        "    data = data.split(\"base64,\")[1]\n",
        "    print(len(data))\n",
        "    base64string += data\n",
        "    print(len(base64string))\n",
        "\n",
        "    video_filename = \"output_\" + str(i) + \".mp4\"\n",
        "    fh = open(video_filename, \"wb\")\n",
        "    fh.write(base64.b64decode(data))\n",
        "    fh.close()"
      ],
      "metadata": {
        "id": "AY1ReC0QMLpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f269bb-dae8-41cd-e769-9628ec7d348a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.txt\n",
            "2512133\n",
            "2512092\n",
            "2512092\n",
            "2.txt\n",
            "2823513\n",
            "2823472\n",
            "5335564\n",
            "3.txt\n",
            "2855093\n",
            "2855052\n",
            "8190616\n",
            "4.txt\n",
            "2833905\n",
            "2833864\n",
            "11024480\n",
            "5.txt\n",
            "2833897\n",
            "2833856\n",
            "13858336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "4h0r3kTKYhCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('./' + video_filename)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(fps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6kdNz_UYkg8",
        "outputId": "13452f8c-c570-43de-be9b-4c271b36fd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.916666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyttsx3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wWq323EZXiB",
        "outputId": "ecd4f656-4dfb-4493-d268-9b15e40dc100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyttsx3\n",
            "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: pyttsx3\n",
            "Successfully installed pyttsx3-2.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vidcap = cv2.VideoCapture(video_filename)\n",
        "def getFrame(sec):\n",
        "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "    hasFrames,image = vidcap.read()\n",
        "    # if hasFrames:\n",
        "    #     cv2.imwrite(\"image\"+str(count)+\".jpg\", image)     # save frame as JPG file\n",
        "    return hasFrames, image\n",
        "sec = 0\n",
        "frameRate = 1 #//it will capture image in each 0.1 second"
      ],
      "metadata": {
        "id": "A2vvqytZaZe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYYuDI0WilCQ",
        "outputId": "f5e01026-6ead-4f7b-e27d-f40bad26842a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=80ba5841568b76d2fb3351bf95dd8e4bd1dca4f6891d1d4d25f2071c5428f1a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: ffmpy\n",
            "Successfully installed ffmpy-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpy\n",
        "\n",
        "def convert(inputted_file):\n",
        "    current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    video_name = str(current_time) + \".avi\"\n",
        "    ff = ffmpy.FFmpeg(inputs={inputted_file : None}, outputs={video_name: ' -c:a mp3 -c:v mpeg4'})\n",
        "    ff.cmd\n",
        "    ff.run()\n",
        "    return video_name\n",
        "convert(video_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9_dEgPSpjU51",
        "outputId": "61c9b94d-eab1-414d-d5e8-12223701a1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'20240619-044317.avi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y2iG-PWn5M3",
        "outputId": "91cb598b-24c9-40b7-f8c2-abaa946ddbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg"
      ],
      "metadata": {
        "id": "b_k2ti-sn3qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probe = ffmpeg.probe(video_filename)\n",
        "# time = float(probe['streams'][0]['duration']) // 2\n",
        "width = probe['streams'][0]['width']\n",
        "\n",
        "# Set how many spots you want to extract a video from.\n",
        "parts = 120\n",
        "\n",
        "intervals = 0.5\n",
        "# intervals = int(intervals)\n",
        "interval_list = [(i * intervals, (i + 1) * intervals) for i in range(parts)]\n",
        "frame_index = 0\n",
        "\n",
        "for item in interval_list:\n",
        "    (\n",
        "        ffmpeg\n",
        "        .input(video_filename, ss=item[1])\n",
        "        .filter('scale', width, -1)\n",
        "        .output('frame_of_video_' + str(latest_timestamp) + '_' + str(frame_index) + '.jpg', vframes=1)\n",
        "        .run()\n",
        "    )\n",
        "    frame_index += 1\n",
        "\n",
        "print(frame_index)"
      ],
      "metadata": {
        "id": "lnxO8sFMn0yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccbd1fa-bc1c-46c1-d09c-e99aed603469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "frames = []\n",
        "final_frame_index = 0\n",
        "for i in range(0, frame_index):\n",
        "  frame_file_name = 'frame_of_video_' + str(latest_timestamp) + '_' + str(i) + '.jpg';\n",
        "  frame = cv2.imread(frame_file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  if (frame is not None):\n",
        "    frames.append(frame)\n",
        "    final_frame_index += 1\n",
        "\n",
        "print(final_frame_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgtzj64H1GF9",
        "outputId": "f6fa3642-da5e-4552-d964-3f2c734fd99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import pyttsx3\n",
        "import ffmpy\n",
        "from scipy.spatial import distance\n",
        "\n",
        "awake = 0\n",
        "sleepy = 0\n",
        "\n",
        "# INITIALIZING THE pyttsx3 SO THAT\n",
        "# ALERT AUDIO MESSAGE CAN BE DELIVERED\n",
        "#engine = pyttsx3.init()\n",
        "\n",
        "# SETTING UP OF CAMERA TO 1 YOU CAN\n",
        "# EVEN CHOOSE 0 IN PLACE OF 1\n",
        "# cap = cv2.VideoCapture('/content/video.mp4')\n",
        "\n",
        "# FACE DETECTION OR MAPPING THE FACE TO\n",
        "# GET THE Eye AND EYES DETECTED\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# PUT THE LOCATION OF .DAT FILE (FILE FOR\n",
        "# PREDECTING THE LANDMARKS ON FACE )\n",
        "dlib_facelandmark = dlib.shape_predictor(\n",
        "\t\"/content/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "# FUNCTION CALCULATING THE ASPECT RATIO FOR\n",
        "# THE Eye BY USING EUCLIDEAN DISTANCE FUNCTION\n",
        "def Detect_Eye(eye):\n",
        "\tpoi_A = distance.euclidean(eye[1], eye[5])\n",
        "\tpoi_B = distance.euclidean(eye[2], eye[4])\n",
        "\tpoi_C = distance.euclidean(eye[0], eye[3])\n",
        "\taspect_ratio_Eye = (poi_A+poi_B)/(2*poi_C)\n",
        "\treturn aspect_ratio_Eye\n",
        "\n",
        "# MAIN LOOP IT WILL RUN ALL THE UNLESS AND\n",
        "# UNTIL THE PROGRAM IS BEING KILLED BY THE USER\n",
        "for i in range(0, final_frame_index):\n",
        "\tgray_scale = frames[i]\n",
        "\n",
        "\tfaces = face_detector(gray_scale)\n",
        "\n",
        "\tfor face in faces:\n",
        "\t\tface_landmarks = dlib_facelandmark(gray_scale, face)\n",
        "\t\tleftEye = []\n",
        "\t\trightEye = []\n",
        "\n",
        "\t\t# THESE ARE THE POINTS ALLOCATION FOR THE\n",
        "\t\t# LEFT EYES IN .DAT FILE THAT ARE FROM 42 TO 47\n",
        "\t\tfor n in range(42, 48):\n",
        "\t\t\tx = face_landmarks.part(n).x\n",
        "\t\t\ty = face_landmarks.part(n).y\n",
        "\t\t\trightEye.append((x, y))\n",
        "\t\t\tnext_point = n+1\n",
        "\t\t\tif n == 47:\n",
        "\t\t\t\tnext_point = 42\n",
        "\t\t\tx2 = face_landmarks.part(next_point).x\n",
        "\t\t\ty2 = face_landmarks.part(next_point).y\n",
        "\t\t\tcv2.line(frame, (x, y), (x2, y2), (0, 255, 0), 1)\n",
        "\n",
        "\t\t# THESE ARE THE POINTS ALLOCATION FOR THE\n",
        "\t\t# RIGHT EYES IN .DAT FILE THAT ARE FROM 36 TO 41\n",
        "\t\tfor n in range(36, 42):\n",
        "\t\t\tx = face_landmarks.part(n).x\n",
        "\t\t\ty = face_landmarks.part(n).y\n",
        "\t\t\tleftEye.append((x, y))\n",
        "\t\t\tnext_point = n+1\n",
        "\t\t\tif n == 41:\n",
        "\t\t\t\tnext_point = 36\n",
        "\t\t\tx2 = face_landmarks.part(next_point).x\n",
        "\t\t\ty2 = face_landmarks.part(next_point).y\n",
        "\t\t\tcv2.line(frame, (x, y), (x2, y2), (255, 255, 0), 1)\n",
        "\n",
        "\t\t# CALCULATING THE ASPECT RATIO FOR LEFT\n",
        "\t\t# AND RIGHT EYE\n",
        "\t\tright_Eye = Detect_Eye(rightEye)\n",
        "\t\tleft_Eye = Detect_Eye(leftEye)\n",
        "\t\tEye_Rat = (left_Eye+right_Eye)/2\n",
        "\n",
        "\t\t# NOW ROUND OF THE VALUE OF AVERAGE MEAN\n",
        "\t\t# OF RIGHT AND LEFT EYES\n",
        "\t\tEye_Rat = round(Eye_Rat, 2)\n",
        "\n",
        "\t\t# THIS VALUE OF 0.25 (YOU CAN EVEN CHANGE IT)\n",
        "\t\t# WILL DECIDE WHETHER THE PERSONS'S EYES ARE CLOSE OR NOT\n",
        "\t\tif Eye_Rat < 0.25:\n",
        "\t\t\tcv2.putText(frame, \"DROWSINESS DETECTED\", (50, 100),\n",
        "\t\t\t\t\t\tcv2.FONT_HERSHEY_PLAIN, 2, (21, 56, 210), 3)\n",
        "\t\t\tcv2.putText(frame, \"Alert!!!! WAKE UP DUDE\", (50, 450),\n",
        "\t\t\t\t\t\tcv2.FONT_HERSHEY_PLAIN, 2, (21, 56, 212), 3)\n",
        "\n",
        "\t\t\t# CALLING THE AUDIO FUNCTION OF TEXT TO\n",
        "\t\t\t# AUDIO FOR ALERTING THE PERSON\n",
        "\t\t\t# engine.say(\"Alert!!!! WAKE UP DUDE\")\n",
        "\t\t\t# engine.runAndWait()\n",
        "\t\t\tprint(\"DROWSINESS DETECTED\")\n",
        "\t\t\tsleepy += 1\n",
        "\t\telse:\n",
        "\t\t\tprint(\"STILL AWAKE\")\n",
        "\t\t\tawake += 1\n",
        "\n",
        "\t#cv2.imshow(\"Drowsiness DETECTOR IN OPENCV2\", frame)\n",
        "\t# key = cv2.waitKey(9)\n",
        "\t# if key == 20:\n",
        "\t# \tbreak\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()\n",
        "print(awake)\n",
        "print(sleepy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "335kGTXGcSXY",
        "outputId": "9473b089-a271-48e4-bf95-03c967c4806e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "DROWSINESS DETECTED\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "STILL AWAKE\n",
            "71\n",
            "58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "record_id = uuid.uuid4()\n",
        "inference = \"Awake\"\n",
        "if sleepy > awake:\n",
        "  inference = \"Sleepy\"\n",
        "\n",
        "inference_table = dynamodb.Table('DrowsinessInferences')\n",
        "inference_table.put_item(\n",
        "   Item={\n",
        "        'RecordId': str(record_id),\n",
        "        'UserId': 'Vimukthi',\n",
        "        'Time': str(latest_timestamp),\n",
        "        'Inference': inference\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTXb9HTK6rrA",
        "outputId": "ee1fecd8-08cb-4866-8616-060a9b48efe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ResponseMetadata': {'RequestId': 'SSD4HK3S3V1DJ8OCT1GPDPCND3VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
              "  'HTTPStatusCode': 200,\n",
              "  'HTTPHeaders': {'server': 'Server',\n",
              "   'date': 'Wed, 19 Jun 2024 05:19:37 GMT',\n",
              "   'content-type': 'application/x-amz-json-1.0',\n",
              "   'content-length': '2',\n",
              "   'connection': 'keep-alive',\n",
              "   'x-amzn-requestid': 'SSD4HK3S3V1DJ8OCT1GPDPCND3VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
              "   'x-amz-crc32': '2745614147'},\n",
              "  'RetryAttempts': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPkFhmhsyF32",
        "outputId": "136d7413-5cda-45d2-b0c4-60ae944809ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.34.140-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.140 (from boto3)\n",
            "  Downloading botocore-1.34.140-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.140->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.140->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.140->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.140 botocore-1.34.140 jmespath-1.0.1 s3transfer-0.10.2\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "import calendar;\n",
        "import time;\n",
        "import base64\n",
        "import cv2\n",
        "import ffmpeg\n",
        "import dlib\n",
        "import uuid\n",
        "\n",
        "from scipy.spatial import distance\n",
        "from boto3.dynamodb.conditions import Key, Attr\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "\n",
        "already_checked_timestamps = set()\n",
        "\n",
        "dynamodb = boto3.resource('dynamodb',\n",
        "    region_name =\"us-east-1\",\n",
        "    aws_access_key_id=\"AKIAZI2LCD2QHF4KI2NZ\",\n",
        "    aws_secret_access_key=\"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\")\n",
        "\n",
        "video_table = dynamodb.Table('FacialVideoData')\n",
        "inference_table = dynamodb.Table('DrowsinessInferences')\n",
        "\n",
        "s3 = boto3.resource('s3',\n",
        "    aws_access_key_id=\"AKIAZI2LCD2QHF4KI2NZ\",\n",
        "    aws_secret_access_key=\"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\")\n",
        "\n",
        "def get_timestamp():\n",
        "  ts = round(time.time() * 1000)\n",
        "  return ts\n",
        "\n",
        "# def get_frames_from_video(video_filename, timestamp):\n",
        "#   probe = ffmpeg.probe(video_filename)\n",
        "#   width = probe['streams'][0]['width']\n",
        "#   # Set how many spots you want to extract a video from.\n",
        "#   parts = 120\n",
        "#   intervals = 0.5\n",
        "#   interval_list = [(i * intervals, (i + 1) * intervals) for i in range(parts)]\n",
        "#   frame_index = 0\n",
        "#   for item in interval_list:\n",
        "#       (\n",
        "#           ffmpeg\n",
        "#           .input(video_filename, ss=item[1])\n",
        "#           .filter('scale', width, -1)\n",
        "#           .output('frame_of_video_' + str(timestamp) + '_' + str(frame_index) + '.jpg', vframes=1)\n",
        "#           .run()\n",
        "#       )\n",
        "#       frame_index += 1\n",
        "\n",
        "#   frames = []\n",
        "#   final_frame_index = 0\n",
        "#   for i in range(0, frame_index):\n",
        "#     frame_file_name = 'frame_' + str(timestamp) + '_' + str(i) + '.jpg';\n",
        "#     frame = cv2.imread(frame_file_name, cv2.IMREAD_GRAYSCALE)\n",
        "#     if (frame is not None):\n",
        "#       frames.append(frame)\n",
        "#       final_frame_index += 1\n",
        "\n",
        "#   return final_frame_index, frames\n",
        "\n",
        "frame_padding = 250 # in milliseconds\n",
        "\n",
        "def detect(video_file):\n",
        "  awake = 0\n",
        "  sleepy = 0\n",
        "\n",
        "  face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "  dlib_facelandmark = dlib.shape_predictor(\n",
        "    \"/content/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "  def Detect_Eye(eye):\n",
        "    poi_A = distance.euclidean(eye[1], eye[5])\n",
        "    poi_B = distance.euclidean(eye[2], eye[4])\n",
        "    poi_C = distance.euclidean(eye[0], eye[3])\n",
        "    aspect_ratio_Eye = (poi_A+poi_B)/(2*poi_C)\n",
        "    return aspect_ratio_Eye\n",
        "\n",
        "  vidcap = cv2.VideoCapture(video_file)\n",
        "\n",
        "  for frame_index in tqdm(range(300)):\n",
        "    vidcap.set(cv2.CAP_PROP_POS_MSEC, frame_padding * frame_index)\n",
        "    hasFrames, frame = vidcap.read()\n",
        "    if not hasFrames or frame_index > 249:\n",
        "      break\n",
        "    else:\n",
        "      frame_index += 1\n",
        "    gray_scale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = face_detector(gray_scale)\n",
        "\n",
        "    for face in faces:\n",
        "      face_landmarks = dlib_facelandmark(gray_scale, face)\n",
        "      leftEye = []\n",
        "      rightEye = []\n",
        "\n",
        "      for n in range(42, 48):\n",
        "        x = face_landmarks.part(n).x\n",
        "        y = face_landmarks.part(n).y\n",
        "        rightEye.append((x, y))\n",
        "        next_point = n+1\n",
        "        if n == 47:\n",
        "          next_point = 42\n",
        "        x2 = face_landmarks.part(next_point).x\n",
        "        y2 = face_landmarks.part(next_point).y\n",
        "        cv2.line(frame, (x, y), (x2, y2), (0, 255, 0), 1)\n",
        "\n",
        "      for n in range(36, 42):\n",
        "        x = face_landmarks.part(n).x\n",
        "        y = face_landmarks.part(n).y\n",
        "        leftEye.append((x, y))\n",
        "        next_point = n+1\n",
        "        if n == 41:\n",
        "          next_point = 36\n",
        "        x2 = face_landmarks.part(next_point).x\n",
        "        y2 = face_landmarks.part(next_point).y\n",
        "        cv2.line(frame, (x, y), (x2, y2), (255, 255, 0), 1)\n",
        "\n",
        "      right_Eye = Detect_Eye(rightEye)\n",
        "      left_Eye = Detect_Eye(leftEye)\n",
        "      Eye_Rat = (left_Eye+right_Eye)/2\n",
        "\n",
        "      Eye_Rat = round(Eye_Rat, 2)\n",
        "\n",
        "      if Eye_Rat < 0.25:\n",
        "        cv2.putText(frame, \"DROWSINESS DETECTED\", (50, 100),\n",
        "              cv2.FONT_HERSHEY_PLAIN, 2, (21, 56, 210), 3)\n",
        "        cv2.putText(frame, \"Alert!!!! WAKE UP DUDE\", (50, 450),\n",
        "              cv2.FONT_HERSHEY_PLAIN, 2, (21, 56, 212), 3)\n",
        "        # print(\"DROWSINESS DETECTED\")\n",
        "        sleepy += 1\n",
        "      else:\n",
        "        # print(\"STILL AWAKE\")\n",
        "        awake += 1\n",
        "  print(str(awake) + \" awakeness and \" + str(sleepy) + \" sleepiness detected\")\n",
        "  return sleepy > awake\n",
        "\n",
        "\n",
        "s3.Bucket(\"facialvideorecordings\").download_file(\"shape_predictor_68_face_landmarks.dat\", 'shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "while True:\n",
        "  scan_timestamp = get_timestamp() - (60000 * 30)\n",
        "  response = video_table.scan(\n",
        "      FilterExpression=Attr('UserId').eq('Vimukthi') & Attr('Time').gt(str(scan_timestamp)) & Attr('StatusOfRecord').eq('Unprocessed')\n",
        "  )\n",
        "\n",
        "  items = response['Items']\n",
        "  if len(items) < 1:\n",
        "    print(\"Not items to detect\\n\")\n",
        "    time.sleep(30)\n",
        "    continue\n",
        "\n",
        "  timestamp = 1000000000000000000000000000000\n",
        "  record_id_of_database_item = None\n",
        "  user_id = None\n",
        "  file_path = None\n",
        "  status = None\n",
        "  for record in items:\n",
        "    record_time = int(record['Time'])\n",
        "    if record_time < timestamp:\n",
        "      timestamp = record_time\n",
        "      record_id_of_database_item = record['RecordId']\n",
        "      user_id = record['UserId']\n",
        "      file_path = record['FilePath']\n",
        "      status = record['StatusOfRecord']\n",
        "  print(\"Processing the recording for the timestamp: \" + str(timestamp) + \" for sleepiness\")\n",
        "\n",
        "  video_filename = file_path + \".mp4\"\n",
        "\n",
        "  s3.Bucket(\"facialvideorecordings\").download_file(file_path , file_path)\n",
        "  with open(file_path, 'r') as file:\n",
        "      base64string = file.read()\n",
        "      file = open(video_filename, \"wb\")\n",
        "      file.write(base64.b64decode(base64string))\n",
        "      file.close()\n",
        "\n",
        "  # frame_index, frames = get_frames_from_video(video_filename, timestamp)\n",
        "  is_sleepy = detect(video_filename)\n",
        "  # already_checked_timestamps.add(timestamp)\n",
        "\n",
        "  record_id = uuid.uuid4()\n",
        "  inference = \"Awake\"\n",
        "  if is_sleepy:\n",
        "    inference = \"Sleepy\"\n",
        "\n",
        "  inference_table.put_item(\n",
        "    Item={\n",
        "          'RecordId': str(record_id),\n",
        "          'UserId': 'Vimukthi',\n",
        "          'Time': str(timestamp),\n",
        "          'Inference': inference\n",
        "      })\n",
        "\n",
        "  delete_response = video_table.delete_item(\n",
        "        Key={\n",
        "            'RecordId': str(record_id_of_database_item),\n",
        "            'UserId': 'Vimukthi'\n",
        "        }\n",
        "    )\n",
        "\n",
        "  update_response = video_table.put_item(\n",
        "      Item={\n",
        "          \"RecordId\": str(record_id_of_database_item),\n",
        "          \"UserId\": user_id,\n",
        "          \"Time\": str(timestamp),\n",
        "          \"FilePath\": file_path,\n",
        "          \"StatusOfRecord\": \"Processed\"})\n",
        "\n",
        "  print(\"Therefore, the inference for timestamp: \" + str(timestamp) + \" is that the user is \" + inference + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qn7-QyuoiJI7",
        "outputId": "166320f7-c159-4069-a437-50e63c0ec636"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Processing the recording for the timestamp: 1720266562551 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 240/300 [00:42<00:10,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53 awakeness and 177 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720266562551 is that the user is Sleepy\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Processing the recording for the timestamp: 1720266620147 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [00:45<00:09,  5.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 awakeness and 236 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720266620147 is that the user is Sleepy\n",
            "\n",
            "Processing the recording for the timestamp: 1720266685620 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 248/300 [00:42<00:08,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 awakeness and 238 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720266685620 is that the user is Sleepy\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Processing the recording for the timestamp: 1720266744400 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 245/300 [00:42<00:09,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 awakeness and 223 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720266744400 is that the user is Sleepy\n",
            "\n",
            "Processing the recording for the timestamp: 1720266800024 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 241/300 [00:45<00:11,  5.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226 awakeness and 8 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720266800024 is that the user is Awake\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Processing the recording for the timestamp: 1720266863621 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [00:44<00:08,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245 awakeness and 4 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720266863621 is that the user is Awake\n",
            "\n",
            "Processing the recording for the timestamp: 1720266926033 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [00:44<00:08,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245 awakeness and 5 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720266926033 is that the user is Awake\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Processing the recording for the timestamp: 1720266978781 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [00:45<00:09,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247 awakeness and 3 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720266978781 is that the user is Awake\n",
            "\n",
            "Processing the recording for the timestamp: 1720267040918 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 248/300 [00:44<00:09,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "246 awakeness and 2 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720267040918 is that the user is Awake\n",
            "\n",
            "Processing the recording for the timestamp: 1720267096596 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 243/300 [00:44<00:10,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239 awakeness and 4 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720267096596 is that the user is Awake\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Processing the recording for the timestamp: 1720267337610 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 240/300 [00:42<00:10,  5.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 awakeness and 196 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720267337610 is that the user is Sleepy\n",
            "\n",
            "Processing the recording for the timestamp: 1720267400566 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [00:44<00:08,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 awakeness and 246 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720267400566 is that the user is Sleepy\n",
            "\n",
            "Not items to detect\n",
            "\n",
            "Processing the recording for the timestamp: 1720267459920 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 247/300 [00:42<00:09,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31 awakeness and 216 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720267459920 is that the user is Sleepy\n",
            "\n",
            "Processing the recording for the timestamp: 1720267517402 for sleepiness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 244/300 [00:44<00:10,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228 awakeness and 5 sleepiness detected\n",
            "Therefore, the inference for timestamp: 1720267517402 is that the user is Awake\n",
            "\n",
            "Not items to detect\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-757fa7dc3a8a>\u001b[0m in \u001b[0;36m<cell line: 143>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not items to detect\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKOX6c7Janjp",
        "outputId": "327af2ff-7bfe-485f-84a8-90b9fbc88f54"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'sample_data': Is a directory\n"
          ]
        }
      ]
    }
  ]
}